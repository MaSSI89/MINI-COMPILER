{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaSSI89/MINI-COMPILER/blob/main/recognize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1sHpHzhIZ3"
      },
      "source": [
        "Import LIbraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qDtUFAWhIZ8"
      },
      "source": [
        "DataProcessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ORRGbzFEhIZ5",
        "outputId": "f02eefd7-7102-4537-ca3f-0b5d9414c676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset: /kaggle/input/hg14-handgesture14-dataset\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_processor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9e5e78f2ada0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gulerosman/hg14-handgesture14-dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_processor' is not defined"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models\n",
        "from torchvision.transforms import transforms\n",
        "import pickle\n",
        "import copy\n",
        "import time\n",
        "import kagglehub\n",
        "\n",
        "dataset_path = kagglehub.dataset_download(\"gulerosman/hg14-handgesture14-dataset\")\n",
        "print(\"Path to dataset:\", dataset_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p50LHsvXhIZ8"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "    def __init__(self, data_path=None, img_size=128):\n",
        "        self.data_path = data_path\n",
        "        self.img_size = img_size\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.X_val = None\n",
        "        self.y_val = None\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "\n",
        "    def load_hg14_dataset(self, download=False):\n",
        "        import os\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        if download:\n",
        "            try:\n",
        "              !kaggle datasets download -d gulerosman/hg14-handgesture14-dataset -p /root/.cache/kagglehub/datasets/gulerosman/hg14-handgesture14-dataset/versions/1 --unzip\n",
        "              print(\"Dataset downloaded successfully.\")\n",
        "            except:\n",
        "                print(\"Please download the HG14 dataset manually from: \")\n",
        "                print(\"https://www.kaggle.com/datasets/gulerosman/hg14-handgesture14-dataset\")\n",
        "                print(\"and place it in the 'data' directory\")\n",
        "                return False\n",
        "\n",
        "        if self.data_path is None:\n",
        "            self.data_path = \"D:\\\\m1\\\\Rnn\\\\projet\\\\HG14-Hand Gesture\"\n",
        "\n",
        "        if not os.path.exists(self.data_path):\n",
        "            print(f\"Dataset not found at {self.data_path}\")\n",
        "            return False\n",
        "\n",
        "        print(\"Loading dataset...\")\n",
        "\n",
        "        class_folders = [f for f in os.listdir(self.data_path)\n",
        "                        if os.path.isdir(os.path.join(self.data_path, f))]\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(class_folders):\n",
        "            class_path = os.path.join(self.data_path, class_name)\n",
        "            print(f\"Processing class {class_name} ({class_idx})...\")\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "                    images.append(img)\n",
        "                    labels.append(class_idx)\n",
        "\n",
        "        X = np.array(images)\n",
        "        y = np.array(labels)\n",
        "\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "        X_train = X_train / 255.0\n",
        "        X_val = X_val / 255.0\n",
        "        X_test = X_test / 255.0\n",
        "\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        self.X_train = torch.FloatTensor(X_train.transpose(0, 3, 1, 2))\n",
        "        self.X_val = torch.FloatTensor(X_val.transpose(0, 3, 1, 2))\n",
        "        self.X_test = torch.FloatTensor(X_test.transpose(0, 3, 1, 2))\n",
        "\n",
        "        self.y_train = torch.LongTensor(y_train)\n",
        "        self.y_val = torch.LongTensor(y_val)\n",
        "        self.y_test = torch.LongTensor(y_test)\n",
        "\n",
        "        self.y_train_onehot = torch.nn.functional.one_hot(self.y_train, num_classes).float()\n",
        "        self.y_val_onehot = torch.nn.functional.one_hot(self.y_val, num_classes).float()\n",
        "        self.y_test_onehot = torch.nn.functional.one_hot(self.y_test, num_classes).float()\n",
        "\n",
        "        print(f\"Dataset processed. {len(X_train)} training, {len(X_val)} validation, {len(X_test)} test samples.\")\n",
        "        return True\n",
        "\n",
        "    def collect_custom_dataset(self, num_classes=14, samples_per_class=100):\n",
        "        import os\n",
        "        import cv2\n",
        "        import time\n",
        "\n",
        "        if not os.path.exists('data/custom_dataset'):\n",
        "            os.makedirs('data/custom_dataset')\n",
        "\n",
        "        cap = cv2.VideoCapture(0)\n",
        "\n",
        "        for class_idx in range(num_classes):\n",
        "            class_dir = f'data/custom_dataset/class_{class_idx}'\n",
        "            os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "            print(f\"Collecting images for gesture class {class_idx}\")\n",
        "            print(\"Position your hand in the frame and press 's' to start capture\")\n",
        "            print(\"Press 'q' to quit\")\n",
        "\n",
        "            wait_key = True\n",
        "            count = 0\n",
        "\n",
        "            while wait_key:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                cv2.putText(frame, f\"Class: {class_idx}, Samples: {count}/{samples_per_class}\",\n",
        "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "                cv2.putText(frame, \"Press 's' to start/pause capture\",\n",
        "                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "                cv2.imshow('Capture', frame)\n",
        "                key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "                if key == ord('s'):\n",
        "                    wait_key = False\n",
        "                elif key == ord('q'):\n",
        "                    cap.release()\n",
        "                    cv2.destroyAllWindows()\n",
        "                    return False\n",
        "\n",
        "            print(\"Capturing... (Press 'p' to pause, 'q' to quit)\")\n",
        "\n",
        "            while count < samples_per_class:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                h, w = frame.shape[:2]\n",
        "                cv2.rectangle(frame, (w//4, h//4), (3*w//4, 3*h//4), (0, 255, 0), 2)\n",
        "\n",
        "                cv2.putText(frame, f\"Class: {class_idx}, Samples: {count}/{samples_per_class}\",\n",
        "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "                cv2.imshow('Capture', frame)\n",
        "                key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "                if key == ord('p'):\n",
        "                    print(\"Paused. Press 's' to resume\")\n",
        "                    wait_pause = True\n",
        "                    while wait_pause:\n",
        "                        key = cv2.waitKey(1) & 0xFF\n",
        "                        if key == ord('s'):\n",
        "                            wait_pause = False\n",
        "                        elif key == ord('q'):\n",
        "                            cap.release()\n",
        "                            cv2.destroyAllWindows()\n",
        "                            return False\n",
        "                elif key == ord('q'):\n",
        "                    cap.release()\n",
        "                    cv2.destroyAllWindows()\n",
        "                    return False\n",
        "\n",
        "                roi = frame[h//4:3*h//4, w//4:3*w//4]\n",
        "                roi = cv2.resize(roi, (self.img_size, self.img_size))\n",
        "                cv2.imwrite(f'{class_dir}/sample_{count}.jpg', roi)\n",
        "                count += 1\n",
        "                time.sleep(0.1)\n",
        "\n",
        "            print(f\"Completed capturing for class {class_idx}\")\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(\"Dataset collection complete.\")\n",
        "\n",
        "        self.data_path = 'data/custom_dataset'\n",
        "        return self.load_custom_dataset()\n",
        "\n",
        "    def load_custom_dataset(self):\n",
        "        import os\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        if not os.path.exists(self.data_path):\n",
        "            print(f\"Custom dataset not found at {self.data_path}\")\n",
        "            return False\n",
        "\n",
        "        class_folders = [f for f in os.listdir(self.data_path)\n",
        "                        if os.path.isdir(os.path.join(self.data_path, f))]\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(sorted(class_folders)):\n",
        "            class_path = os.path.join(self.data_path, class_name)\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                          if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "                    images.append(img)\n",
        "                    labels.append(class_idx)\n",
        "\n",
        "        X = np.array(images)\n",
        "        y = np.array(labels)\n",
        "\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "        X_train = X_train / 255.0\n",
        "        X_val = X_val / 255.0\n",
        "        X_test = X_test / 255.0\n",
        "\n",
        "        num_classes = len(np.unique(y))\n",
        "\n",
        "        self.X_train = torch.FloatTensor(X_train.transpose(0, 3, 1, 2))\n",
        "        self.X_val = torch.FloatTensor(X_val.transpose(0, 3, 1, 2))\n",
        "        self.X_test = torch.FloatTensor(X_test.transpose(0, 3, 1, 2))\n",
        "\n",
        "        self.y_train = torch.LongTensor(y_train)\n",
        "        self.y_val = torch.LongTensor(y_val)\n",
        "        self.y_test = torch.LongTensor(y_test)\n",
        "\n",
        "        self.y_train_onehot = torch.nn.functional.one_hot(self.y_train, num_classes).float()\n",
        "        self.y_val_onehot = torch.nn.functional.one_hot(self.y_val, num_classes).float()\n",
        "        self.y_test_onehot = torch.nn.functional.one_hot(self.y_test, num_classes).float()\n",
        "\n",
        "        print(f\"Custom dataset processed. {len(X_train)} training, {len(X_val)} validation, {len(X_test)} test samples.\")\n",
        "        return True\n",
        "\n",
        "    def load_gesture_dataset(self):\n",
        "        import os\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        if not os.path.exists(self.data_path):\n",
        "            print(f\"Dataset not found at {self.data_path}\")\n",
        "            return False\n",
        "\n",
        "        print(\"Loading gesture dataset...\")\n",
        "\n",
        "        print(os.listdir(self.data_path))\n",
        "        for item in os.listdir(self.data_path):\n",
        "            print(item)\n",
        "\n",
        "        class_folders = [f for f in os.listdir(self.data_path)\n",
        "                        if os.path.isdir(os.path.join(self.data_path, f)) and f.startswith('Gesture_')]\n",
        "\n",
        "        class_folders.sort()\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for class_folder in class_folders:\n",
        "            class_idx = int(class_folder.split('_')[1])\n",
        "            class_path = os.path.join(self.data_path, class_folder)\n",
        "            print(f\"Processing {class_folder} (class {class_idx})...\")\n",
        "\n",
        "            image_files = [f for f in os.listdir(class_path)\n",
        "                        if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "            for img_file in image_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                    img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "                    images.append(img)\n",
        "                    labels.append(class_idx)\n",
        "\n",
        "        X = np.array(images)\n",
        "        y = np.array(labels)\n",
        "\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val)\n",
        "\n",
        "        X_train = X_train / 255.0\n",
        "        X_val = X_val / 255.0\n",
        "        X_test = X_test / 255.0\n",
        "\n",
        "        self.X_train = torch.FloatTensor(X_train.transpose(0, 3, 1, 2))\n",
        "        self.X_val = torch.FloatTensor(X_val.transpose(0, 3, 1, 2))\n",
        "        self.X_test = torch.FloatTensor(X_test.transpose(0, 3, 1, 2))\n",
        "\n",
        "        num_classes = 14\n",
        "\n",
        "        self.y_train = torch.LongTensor(y_train)\n",
        "        self.y_val = torch.LongTensor(y_val)\n",
        "        self.y_test = torch.LongTensor(y_test)\n",
        "\n",
        "        self.y_train_onehot = torch.nn.functional.one_hot(self.y_train, num_classes).float()\n",
        "        self.y_val_onehot = torch.nn.functional.one_hot(self.y_val, num_classes).float()\n",
        "        self.y_test_onehot = torch.nn.functional.one_hot(self.y_test, num_classes).float()\n",
        "\n",
        "        print(f\"Dataset processed. {len(X_train)} training, {len(X_val)} validation, {len(X_test)} test samples.\")\n",
        "        return True\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.X_train, self.y_train_onehot, self.X_val, self.y_val_onehot, self.X_test, self.y_test_onehot\n",
        "\n",
        "    def save_data(self, filename='data/processed_data.pkl'):\n",
        "        import pickle\n",
        "        import os\n",
        "\n",
        "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "        data = {\n",
        "            'X_train': self.X_train,\n",
        "            'y_train': self.y_train_onehot,\n",
        "            'X_val': self.X_val,\n",
        "            'y_val': self.y_val_onehot,\n",
        "            'X_test': self.X_test,\n",
        "            'y_test': self.y_test_onehot\n",
        "        }\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "        print(f\"Data saved to {filename}\")\n",
        "\n",
        "    def load_data(self, filename='data/processed_data.pkl'):\n",
        "        import pickle\n",
        "        import os\n",
        "\n",
        "        if not os.path.exists(filename):\n",
        "            print(f\"Data file {filename} not found\")\n",
        "            return False\n",
        "\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        self.X_train = data['X_train']\n",
        "        self.y_train_onehot = data['y_train']\n",
        "        self.X_val = data['X_val']\n",
        "        self.y_val_onehot = data['y_val']\n",
        "        self.X_test = data['X_test']\n",
        "        self.y_test_onehot = data['y_test']\n",
        "\n",
        "        print(f\"Data loaded from {filename}\")\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dk7WpFUhIZ_"
      },
      "source": [
        "## Gesture Recognition Model\n",
        "\n",
        "The `GestureRecognitionModel` class defines the CNN and transfer learning models, training, evaluation, and prediction methods.\n",
        "CODE SELL GESTURERECOGNITION MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "klmbNzFrhIZ_"
      },
      "outputs": [],
      "source": [
        "class GestureRecognitionModel:\n",
        "    def __init__(self, input_shape=(3, 128, 128), num_classes=14):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.model = None\n",
        "        self.history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def build_custom_cnn(self):\n",
        "        model = nn.Sequential(\n",
        "            nn.Conv2d(self.input_shape[0], 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 8 * 8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, self.num_classes)\n",
        "        )\n",
        "        self.model = model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "        return model\n",
        "\n",
        "    def build_mobilenet(self):\n",
        "        base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
        "        for param in base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        num_features = base_model.classifier[1].in_features\n",
        "        base_model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_features, self.num_classes)\n",
        "        )\n",
        "        self.model = base_model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "        return self.model\n",
        "\n",
        "    def build_vgg16(self):\n",
        "        base_model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "        for param in base_model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        base_model.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, self.num_classes)\n",
        "        )\n",
        "        self.model = base_model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n",
        "        return self.model\n",
        "\n",
        "    def build_ensemble_model(self, model_paths):\n",
        "        models_list = []\n",
        "        for path in model_paths:\n",
        "            model = torch.load(path)\n",
        "            model.eval()\n",
        "            models_list.append(model.to(self.device))\n",
        "        self.ensemble_models = models_list\n",
        "        return models_list\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):\n",
        "        if self.model is None:\n",
        "            print(\"Model not built. Please build a model first.\")\n",
        "            return\n",
        "        train_dataset = TensorDataset(X_train, y_train)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_dataset = TensorDataset(X_val, y_val)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "        best_val_loss = float('inf')\n",
        "        patience = 10\n",
        "        patience_counter = 0\n",
        "        best_model_weights = None\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                if labels.shape[1] > 1:\n",
        "                    labels = torch.argmax(labels, dim=1)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            train_loss = running_loss / len(train_loader.dataset)\n",
        "            train_acc = correct / total\n",
        "            self.model.eval()\n",
        "            val_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "                    if labels.shape[1] > 1:\n",
        "                        labels = torch.argmax(labels, dim=1)\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            val_acc = correct / total\n",
        "            print(f'Epoch {epoch+1}/{epochs} - '\n",
        "                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
        "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                patience_counter = 0\n",
        "                best_model_weights = copy.deepcopy(self.model.state_dict())\n",
        "                torch.save(self.model, 'models/best_model.pth')\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f'Early stopping triggered after {epoch+1} epochs')\n",
        "                    break\n",
        "        if best_model_weights is not None:\n",
        "            self.model.load_state_dict(best_model_weights)\n",
        "        return self.history\n",
        "\n",
        "    def evaluate(self, X_test, y_test, batch_size=32):\n",
        "        if self.model is None:\n",
        "            print(\"Model not built. Please build a model first.\")\n",
        "            return\n",
        "        test_dataset = TensorDataset(X_test, y_test)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                if labels.shape[1] > 1:\n",
        "                    labels = torch.argmax(labels, dim=1)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                test_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        test_loss = test_loss / len(test_loader.dataset)\n",
        "        test_acc = correct / total\n",
        "        print(f\"Test loss: {test_loss:.4f}\")\n",
        "        print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "        return [test_loss, test_acc]\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.model is None:\n",
        "            print(\"Model not built. Please build a model first.\")\n",
        "            return None\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        X = X.to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        return probabilities.cpu().numpy()\n",
        "\n",
        "    def predict_ensemble(self, X):\n",
        "        if not hasattr(self, 'ensemble_models') or len(self.ensemble_models) == 0:\n",
        "            print(\"Ensemble models not loaded. Please build ensemble models first.\")\n",
        "            return None\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.FloatTensor(X)\n",
        "        X = X.to(self.device)\n",
        "        predictions = []\n",
        "        for model in self.ensemble_models:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(X)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                predictions.append(probabilities.cpu().numpy())\n",
        "        ensemble_pred = np.mean(predictions, axis=0)\n",
        "        return ensemble_pred\n",
        "\n",
        "    def save_model(self, filepath='models/gesture_model.pth'):\n",
        "        if self.model is None:\n",
        "            print(\"Model not built. Please build a model first.\")\n",
        "            return\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
        "        torch.save(self.model, filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath='models/gesture_model.pth'):\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Model file {filepath} not found\")\n",
        "            return False\n",
        "        self.model = torch.load(filepath)\n",
        "        self.model.to(self.device)\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        return True\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        if not self.history['train_loss']:\n",
        "            print(\"No training history available.\")\n",
        "            return\n",
        "        os.makedirs('logs', exist_ok=True)\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['train_acc'])\n",
        "        plt.plot(self.history['val_acc'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['train_loss'])\n",
        "        plt.plot(self.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('logs/training_history.png')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo-vpQY0hIaC"
      },
      "source": [
        "## Training Workflow\n",
        "\n",
        "The following function orchestrates the data loading, model building, training, evaluation, and saving.\n",
        "CODE CELL , TRAIN GESTURE RECOGNITION MODEL FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DJxX-mllhIaC"
      },
      "outputs": [],
      "source": [
        "def train_gesture_recognition_model():\n",
        "    # 1. Initialize the data processor with path to your dataset\n",
        "\n",
        "    data_processor = DataProcessor(data_path=\"/root/.cache/kagglehub/datasets/gulerosman/hg14-handgesture14-dataset/versions/1\", img_size=128)\n",
        "    print(os.listdir(data_processor.data_path))\n",
        "\n",
        "    # 2. Load and process the gesture dataset\n",
        "    success = data_processor.load_gesture_dataset()\n",
        "    if not success:\n",
        "        print(\"Failed to load dataset\")\n",
        "        return\n",
        "\n",
        "    # 3. Get the processed data\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = data_processor.get_data()\n",
        "\n",
        "    # 4. Save the processed data (optional)\n",
        "    data_processor.save_data('data/gesture_dataset.pkl')\n",
        "\n",
        "    # 5. Initialize the model for 14 gesture classes\n",
        "    model = GestureRecognitionModel(input_shape=(3, 128, 128), num_classes=14)\n",
        "\n",
        "    # 6. Build the model (you can choose from different architectures)\n",
        "    # Option 1: Custom CNN\n",
        "    model.build_custom_cnn()\n",
        "    # Option 2: MobileNet transfer learning\n",
        "    # model.build_mobilenet()\n",
        "    # Option 3: VGG16 transfer learning\n",
        "    # model.build_vgg16()\n",
        "\n",
        "    # 7. Train the model\n",
        "    history = model.train(X_train, y_train, X_val, y_val, epochs=50, batch_size=32)\n",
        "\n",
        "    # 8. Evaluate on test set\n",
        "    test_results = model.evaluate(X_test, y_test)\n",
        "\n",
        "    # 9. Save the trained model\n",
        "    model.save_model('models/gesture_recognition_model.pth')\n",
        "\n",
        "    # 10. Plot training history\n",
        "    model.plot_training_history()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjoOxkM1hIaD"
      },
      "source": [
        "Run TRAINING:\n",
        "Execute the training workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS2uu5wxhIaD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gqGMXQwZhIaE",
        "outputId": "8f285deb-7f71-4cac-b898-58de8508d7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HG14']\n",
            "Loading gesture dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2f8144b0cea4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_gesture_recognition_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-dff56c4789e4>\u001b[0m in \u001b[0;36mtrain_gesture_recognition_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 2. Load and process the gesture dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gesture_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to load dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-8b89e262b0a2>\u001b[0m in \u001b[0;36mload_gesture_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         X_train_val, X_test, y_train_val, y_test = train_test_split(\n\u001b[0m\u001b[1;32m    281\u001b[0m             X, y, test_size=0.1, random_state=42, stratify=y)\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_gesture_recognition_model()\n",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}